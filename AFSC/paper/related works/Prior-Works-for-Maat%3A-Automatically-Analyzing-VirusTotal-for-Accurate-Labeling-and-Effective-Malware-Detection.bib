@article{f74804eaf20b71da1ad2ebbbb429595c133459c8,
title = {AVclass: A Tool for Massive Malware Labeling},
year = {2016},
url = {https://www.semanticscholar.org/paper/f74804eaf20b71da1ad2ebbbb429595c133459c8},
abstract = {Labeling a malicious executable as a variant of a known family is important for security applications such as triage, lineage, and for building reference datasets in turn used for evaluating malware clustering and training malware classification approaches. Oftentimes, such labeling is based on labels output by antivirus engines. While AV labels are well-known to be inconsistent, there is often no other information available for labeling, thus security analysts keep relying on them. However, current approaches for extracting family information from AV labels are manual and inaccurate. In this work, we describe AVclass, an automatic labeling tool that given the AV labels for a, potentially massive, number of samples outputs the most likely family names for each sample. AVclass implements novel automatic techniques to address 3 key challenges: normalization, removal of generic tokens, and alias detection. We have evaluated AVclass on 10 datasets comprising 8.9 M samples, larger than any dataset used by malware clustering and classification works. AVclass leverages labels from any AV engine, e.g., all 99 AV engines seen in VirusTotal, the largest engine set in the literature. AVclass’s clustering achieves F1 measures up to 93.9 on labeled datasets and clusters are labeled with fine-grained family names commonly used by the AV vendors. We release AVclass to the community.},
author = {Marcos Sebastián and Richard Rivera and Platon Kotzias and Juan Caballero},
doi = {10.1007/978-3-319-45719-2_11},
}

@article{12ef153d9c7ccc374d56acf34b59fb2eaec6f755,
title = {Dissecting Android Malware: Characterization and Evolution},
year = {2012},
url = {https://www.semanticscholar.org/paper/12ef153d9c7ccc374d56acf34b59fb2eaec6f755},
abstract = {The popularity and adoption of smart phones has greatly stimulated the spread of mobile malware, especially on the popular platforms such as Android. In light of their rapid growth, there is a pressing need to develop effective solutions. However, our defense capability is largely constrained by the limited understanding of these emerging mobile malware and the lack of timely access to related samples. In this paper, we focus on the Android platform and aim to systematize or characterize existing Android malware. Particularly, with more than one year effort, we have managed to collect more than 1,200 malware samples that cover the majority of existing Android malware families, ranging from their debut in August 2010 to recent ones in October 2011. In addition, we systematically characterize them from various aspects, including their installation methods, activation mechanisms as well as the nature of carried malicious payloads. The characterization and a subsequent evolution-based study of representative families reveal that they are evolving rapidly to circumvent the detection from existing mobile anti-virus software. Based on the evaluation with four representative mobile security software, our experiments show that the best case detects 79.6% of them while the worst case detects only 20.2% in our dataset. These results clearly call for the need to better develop next-generation anti-mobile-malware solutions.},
author = {Yajin Zhou and Xuxian Jiang},
journal = {2012 IEEE Symposium on Security and Privacy},
volume = {},
pages = {95-109},
doi = {10.1109/SP.2012.16},
}

@article{0b38a236d2377068408309f1d31e5c5fc5eedd0b,
title = {DREBIN: Effective and Explainable Detection of Android Malware in Your Pocket},
year = {2014},
url = {https://www.semanticscholar.org/paper/0b38a236d2377068408309f1d31e5c5fc5eedd0b},
abstract = {Malicious applications pose a threat to the security of the Android platform. The growing amount and diversity of these applications render conventional defenses largely ineffective and thus Android smartphones often remain unprotected from novel malware. In this paper, we propose DREBIN, a lightweight method for detection of Android malware that enables identifying malicious applications directly on the smartphone. As the limited resources impede monitoring applications at run-time, DREBIN performs a broad static analysis, gathering as many features of an application as possible. These features are embedded in a joint vector space, such that typical patterns indicative for malware can be automatically identified and used for explaining the decisions of our method. In an evaluation with 123,453 applications and 5,560 malware samples DREBIN outperforms several related approaches and detects 94% of the malware with few false alarms, where the explanations provided for each detection reveal relevant properties of the detected malware. On five popular smartphones, the method requires 10 seconds for an analysis on average, rendering it suitable for checking downloaded applications directly on the device.},
author = {Dan Arp and Michael Spreitzenbarth and M. Hubner and Hugo Gascon and K. Rieck},
doi = {10.14722/NDSS.2014.23247},
}

@article{c58e3b32bc88ed3d8e7bcdf0523eb27057bd7d0f,
title = {Deep Ground Truth Analysis of Current Android Malware},
year = {2017},
url = {https://www.semanticscholar.org/paper/c58e3b32bc88ed3d8e7bcdf0523eb27057bd7d0f},
abstract = {To build effective malware analysis techniques and to evaluate new detection tools, up-to-date datasets reflecting the current Android malware landscape are essential. For such datasets to be maximally useful, they need to contain reliable and complete information on malware’s behaviors and techniques used in the malicious activities. Such a dataset shall also provide a comprehensive coverage of a large number of types of malware. The Android Malware Genome created circa 2011 has been the only well-labeled and widely studied dataset the research community had easy access to (As of 12/21/2015 the Genome authors have stopped supporting the dataset sharing due to resource limitation). But not only is it outdated and no longer represents the current Android malware landscape, it also does not provide as detailed information on malware’s behaviors as needed for research. Thus it is urgent to create a high-quality dataset for Android malware. While existing information sources such as VirusTotal are useful, to obtain the accurate and detailed information for malware behaviors, deep manual analysis is indispensable. In this work we present our approach to preparing a large Android malware dataset for the research community. We leverage existing anti-virus scan results and automation techniques in categorizing our large dataset (containing 24,650 malware app samples) into 135 varieties (based on malware behavioral semantics) which belong to 71 malware families. For each variety, we select three samples as representatives, for a total of 405 malware samples, to conduct in-depth manual analysis. Based on the manual analysis result we generate detailed descriptions of each malware variety’s behaviors and include them in our dataset. We also report our observations on the current landscape of Android malware as depicted in the dataset. Furthermore, we present detailed documentation of the process used in creating the dataset, including the guidelines for the manual analysis. We make our Android malware dataset available to the research community.},
author = {Fengguo Wei and Yuping Li and Sankardas Roy and Xinming Ou and Wu Zhou},
doi = {10.1007/978-3-319-60876-1_12},
}

@article{6ef3b5a0af396e42711aab8ffbfb1728c2cb95b2,
title = {AV-Meter: An Evaluation of Antivirus Scans and Labels},
year = {2014},
url = {https://www.semanticscholar.org/paper/6ef3b5a0af396e42711aab8ffbfb1728c2cb95b2},
abstract = {Antivirus scanners are designed to detect malware and, to a lesser extent, to label detections based on a family association. The labeling provided by AV vendors has many applications such as guiding efforts of disinfection and countermeasures, intelligence gathering, and attack attribution, among others. Furthermore, researchers rely on AV labels to establish a baseline of ground truth to compare their detection and classification algorithms. This is done despite many papers pointing out the subtle problem of relying on AV labels. However, the literature lacks any systematic study on validating the performance of antivirus scanners, and the reliability of those labels or detection.},
author = {Aziz Mohaisen and Omar Alrawi},
doi = {10.1007/978-3-319-08509-8_7},
}

@article{119cc98a13db1959e45bfdd6c6760741fa49947d,
title = {Better Malware Ground Truth: Techniques for Weighting Anti-Virus Vendor Labels},
year = {2015},
url = {https://www.semanticscholar.org/paper/119cc98a13db1959e45bfdd6c6760741fa49947d},
abstract = {We examine the problem of aggregating the results of multiple anti-virus (AV) vendors' detectors into a single authoritative ground-truth label for every binary. To do so, we adapt a well-known generative Bayesian model that postulates the existence of a hidden ground truth upon which the AV labels depend. We use training based on Expectation Maximization for this fully unsupervised technique. We evaluate our method using 279,327 distinct binaries from VirusTotal, each of which appeared for the first time between January 2012 and June 2014. Our evaluation shows that our statistical model is consistently more accurate at predicting the future-derived ground truth than all unweighted rules of the form "k out of n" AV detections. In addition, we evaluate the scenario where partial ground truth is available for model building. We train a logistic regression predictor on the partial label information. Our results show that as few as a 100 randomly selected training instances with ground truth are enough to achieve 80% true positive rate for 0.1% false positive rate. In comparison, the best unweighted threshold rule provides only 60% true positive rate at the same false positive rate.},
author = {Alex Kantchelian and M. Tschantz and Sadia Afroz and Brad Miller and Vaishaal Shankar and Rekha Bachwani and A. Joseph and J. Tygar},
journal = {Proceedings of the 8th ACM Workshop on Artificial Intelligence and Security},
volume = {},
pages = {},
doi = {10.1145/2808769.2808780},
}

@article{f73bf84e00455987f12b1f523f0b83769fe7131c,
title = {Euphony: Harmonious Unification of Cacophonous Anti-Virus Vendor Labels for Android Malware},
year = {2017},
url = {https://www.semanticscholar.org/paper/f73bf84e00455987f12b1f523f0b83769fe7131c},
abstract = {Android malware is now pervasive and evolving rapidly. Thousands of malware samples are discovered every day with new models of attacks. The growth of these threats has come hand in hand with the proliferation of collective repositories sharing the latest specimens. Having access to a large number of samples opens new research directions aiming at efficiently vetting apps. However, automatically inferring a reference ground-truth from those repositories is not straightforward and can inadvertently lead to unforeseen misconceptions. On the one hand, samples are often mis-labeled as different parties use distinct naming schemes for the same sample. On the other hand, samples are frequently mis-classified due to conceptual errors made during labeling processes. In this paper, we analyze the associations between all labels given by different vendors and we propose a system called EUPHONY to systematically unify common samples into family groups. The key novelty of our approach is that no a-priori knowledge on malware families is needed. We evaluate our approach using reference datasets and more than 0.4 million additional samples outside of these datasets. Results show that EUPHONY provides competitive performance against the state-of-the-art.},
author = {M. Hurier and Guillermo Suarez-Tangil and S. K. Dash and Tegawendé F. Bissyandé and Y. L. Traon and Jacques Klein and L. Cavallaro},
journal = {2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)},
volume = {},
pages = {425-435},
doi = {10.1109/MSR.2017.57},
}

@article{7833ac4461d6ebc5c29197ce6a7926985b1af1b5,
title = {Finding Non-trivial Malware Naming Inconsistencies},
year = {2011},
url = {https://www.semanticscholar.org/paper/7833ac4461d6ebc5c29197ce6a7926985b1af1b5},
abstract = {Malware analysts, and in particular antivirus vendors, never agreed on a single naming convention for malware specimens. This leads to confusion and difficulty—more for researchers than for practitioners—for example, when comparing coverage of different antivirus engines, when integrating and systematizing known threats, or comparing the classifications given by different detectors. Clearly, solving naming inconsistencies is a very difficult task, as it requires that vendors agree on a unified naming convention. More importantly, solving inconsistencies is impossible without knowing exactly where they are. Therefore, in this paper we take a step back and concentrate on the problem of finding inconsistencies. To this end, we first represent each vendor's naming convention with a graph-based model. Second, we give a precise definition of inconsistency with respect to these models. Third, we define two quantitative measures to calculate the overall degree of inconsistency between vendors. In addition, we propose a fast algorithm that finds non-trivial (i.e., beyond syntactic differences) inconsistencies. Our experiments on four major antivirus vendors and 98,798 real-world malware samples confirm anecdotal observations that different vendors name viruses differently. More importantly, we were able to find inconsistencies that cannot be inferred at all by looking solely at the syntax.},
author = {F. Maggi and A. Bellini and G. Salvaneschi and S. Zanero},
doi = {10.1007/978-3-642-25560-1_10},
}

@article{1e2681da9bed9abc8f47cd0d3834cb8d820a63b8,
title = {On the Lack of Consensus in Anti-Virus Decisions: Metrics and Insights on Building Ground Truths of Android Malware},
year = {2016},
url = {https://www.semanticscholar.org/paper/1e2681da9bed9abc8f47cd0d3834cb8d820a63b8},
abstract = {There is generally a lack of consensus in Antivirus AV engines' decisions on a given sample. This challenges the building of authoritative ground-truth datasets. Instead, researchers and practitioners may rely on unvalidated approaches to build their ground truth, e.g., by considering decisions from a selected set of Antivirus vendors or by setting up a threshold number of positive detections before classifying a sample. Both approaches are biased as they implicitly either decide on ranking AV products, or they consider that all AV decisions have equal weights. In this paper, we extensively investigate the lack of agreement among AV engines. To that end, we propose a set of metrics that quantitatively describe the different dimensions of this lack of consensus. We show how our metrics can bring important insights by using the detection results of 66 AV products on 2 million Android apps as a case study. Our analysis focuses not only on AV binary decision but also on the notoriously hard problem of labels that AVs associate with suspicious files, and allows to highlight biases hidden in the collection of a malware ground truth--a foundation stone of any malware detection approach.},
author = {M. Hurier and Kevin Allix and Tegawendé F. Bissyandé and Jacques Klein and Y. L. Traon},
doi = {10.1007/978-3-319-40667-1_8},
}

@article{128add3f0e727b73b3df0ca13b4e818d543bdd98,
title = {AndroZoo: Collecting Millions of Android Apps for the Research Community},
year = {2016},
url = {https://www.semanticscholar.org/paper/128add3f0e727b73b3df0ca13b4e818d543bdd98},
abstract = {We present a growing collection of Android Applications col-lected from several sources, including the official GooglePlay app market. Our dataset, AndroZoo, currently contains more than three million apps, each of which has beenanalysed by tens of different AntiVirus products to knowwhich applications are detected as Malware. We provide thisdataset to contribute to ongoing research efforts, as well asto enable new potential research topics on Android Apps.By releasing our dataset to the research community, we alsoaim at encouraging our fellow researchers to engage in reproducible experiments.},
author = {Kevin Allix and Tegawendé F. Bissyandé and Jacques Klein and Y. L. Traon},
journal = {2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)},
volume = {},
pages = {468-471},
doi = {10.1145/2901739.2903508},
}
