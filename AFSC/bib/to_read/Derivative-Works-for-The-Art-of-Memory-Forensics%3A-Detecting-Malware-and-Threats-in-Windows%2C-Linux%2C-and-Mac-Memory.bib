@article{da9e9968b7dc55c016c127c04e5ce88d568644f7,
title = {Forensic acquisition and analysis of volatile data in memory=Forensische Sicherung und Auswertung flüchtiger Daten im Hauptspeicher},
year = {2013},
url = {https://www.semanticscholar.org/paper/da9e9968b7dc55c016c127c04e5ce88d568644f7},
abstract = {Standard procedures in computer forensics mainly describe the acquisition and analysis of persistent data, e.g., of hard drives or attached devices. However, due to the increasing storage capacity of these media and, correspondingly, significantly larger data volumes, creating forensically-sound duplicates and recovering valuable artifacts in time gets more and more challenging. Moreover, with the wide availability of free and easy-to-use encryption technologies, a growing number of individuals actively try to protect personal information against unauthorized access. If a suspect is unwilling to share the respective decryption key such measures can therefore quickly thwart an investigation. Last but not least, many sophisticated malicious applications entirely run in memory to date and do not leave any traces on hard disks anymore. Solely focusing on traditional sources can thus lead to an incomplete or inaccurate picture of an incident. In order to cope with these issues, researchers have proposed alternative investigative strategies and extracting pieces of evidence from a computer's RAM. For this purpose, a so-called memory snapshot is taken and inspected offline on a trusted workstation. These activities known as memory forensics have gained broad attention among practitioners over the last years, primarily because operations are repeatable and may be safely verified by other experts without polluting the system environment as, for instance, in a live response situation. 
 
In this thesis, we give a comprehensive overview of fundamental concepts and approaches for seizing as well as examining volatile information. It consists of two parts: In the first part, we formalize criteria for sound memory imaging and illustrate the characteristics, benefits, and drawbacks of proven acquisition technologies available on the market to date. As we will see, especially for software-based solutions it is difficult to produce reliable memory snapshots, because the system state cannot be effectively frozen during runtime. With the help of an evaluation platform that we have developed in the course of the dissertation period, the performance and quality of software imagers can be thoroughly assessed for the first time. 
 
In the second part of this thesis, we explain how common system compromise and manipulation techniques as they are typically employed by rootkits or other types of intelligent malware can be discovered during memory analysis. We also present rkfinder, a new plug-in for the popular, open source forensic suite DFF that facilitates some of these tasks. Rkfinder implements cross-viewing algorithms for checking the integrity of a machine and detecting possible inconsistencies that indicate the presence of a threat. By automatically highlighting suspicious resources that are likely to have been tampered with, even less experienced investigators are able to identify system areas that require particular attention. Thereby, potential sources of an intrusion can be quickly found and addressed.},
author = {Stefan Vömel},
}

@article{efa4c827e316e8c9b20e0441b0cf9269761e2915,
title = {Introducing the Temporal Dimension to Memory Forensics},
year = {2019},
url = {https://www.semanticscholar.org/paper/efa4c827e316e8c9b20e0441b0cf9269761e2915},
abstract = {Kickstarted by the Digital Forensic Research Workshop (DFRWS) conference in 2005, modern memory analysis is now one of most active areas of computer forensics and it mostly focuses on techniques to locate key operating system data structures and extract high-level information. These techniques work on the assumption that the information inside a memory dump is consistent and the copy of the physical memory was obtained in an atomic operation. Unfortunately, this is seldom the case in real investigations, where software acquisition tools record information while the rest of the system is running. Thus, since the content of the memory is changing very rapidly, the resulting memory dump may contain inconsistent data. While this problem is known, its consequences are unclear and often overlooked. Unfortunately, errors can be very subtle and can affect the results of an analysis in ways that are difficult to detect. In this article, we argue that memory forensics should also consider the time in which each piece of data was acquired. This new temporal dimension provides a preliminary way to assess the reliability of a given result and opens the door to new research directions that can minimize the effect of the acquisition time or detect inconsistencies. To support our hypothesis, we conducted several experiments to show that inconsistencies are very frequent and can negatively impact an analysis. We then discuss modifications we made to popular memory forensic tools to make the temporal dimension explicit during the analysis and to minimize its effect by resorting to a locality-based acquisition.},
author = {Fabio Pagani and Oleksii Fedorov and D. Balzarotti},
journal = {ACM Transactions on Privacy and Security (TOPS)},
volume = {22},
pages = {1 - 21},
doi = {10.1145/3310355},
}

@article{e362edd8953ced590d79f5d15360233131913c80,
title = {A survey of main memory acquisition and analysis techniques for the windows operating system},
year = {2011},
url = {https://www.semanticscholar.org/paper/e362edd8953ced590d79f5d15360233131913c80},
abstract = {Traditional, persistent data-oriented approaches in computer forensics face some limitations regarding a number of technological developments, e.g., rapidly increasing storage capabilities of hard drives, memory-resident malicious software applications, or the growing use of encryption routines, that make an in-time investigation more and more difficult. In order to cope with these issues, security professionals have started to examine alternative data sources and emphasize the value of volatile system information in RAM more recently. In this paper, we give an overview of the prevailing techniques and methods to collect and analyze a computer's memory. We describe the characteristics, benefits, and drawbacks of the individual solutions and outline opportunities for future research in this evolving field of IT security.},
author = {Stefan Vömel and F. Freiling},
journal = {Digit. Investig.},
volume = {8},
pages = {3-22},
doi = {10.1016/j.diin.2011.06.002},
}

@article{9133478dafcaea102c14ea963928ddb0f4f73189,
title = {Correctness, atomicity, and integrity: Defining criteria for forensically-sound memory acquisition},
year = {2012},
url = {https://www.semanticscholar.org/paper/9133478dafcaea102c14ea963928ddb0f4f73189},
abstract = {Abstract While procedures for forensic memory analysis have been well described in the literature, the actual data acquisition process has been researched to a lesser degree. In particular, even though forensic analysts commonly agree that a memory snapshot should be “correct”, “sound”, and “reliable”, the meaning of these terms still remains informal and vague. In this paper, we formalize three fundamental criteria, correctness , atomicity , and integrity , that determine the quality of a forensic memory image. We illustrate the criteria with the help of a number of intuitive examples, discuss the meaning of forensic soundness as well as outline implications and challenges for memory acquisition solutions available on the market to date.},
author = {Stefan Vömel and F. Freiling},
journal = {Digit. Investig.},
volume = {9},
pages = {125-137},
doi = {10.1016/j.diin.2012.04.005},
}

@article{6d26be83b674231a301e7bed762895f14e613f66,
title = {On the Viability of Memory Forensics in Compromised Environments},
year = {2015},
url = {https://www.semanticscholar.org/paper/6d26be83b674231a301e7bed762895f14e613f66},
abstract = {Memory forensics has become a powerful tool for the detection and analysis of malicious software. It provides investigators with an impartial view of a system, exposing hidden processes, threads, and network connections, by acquiring and analyzing physical memory. Because malicious software must be at least partially resident in memory in order to execute, it cannot remove all its traces from RAM. However, the memory acquisition process is vulnerable to subversion in compromised environments. Malicious software can employ anti-forensic techniques to intercept the acquisition and filter memory contents while they are copied. In this thesis, we analyze 12 popular memory acquisition tools for Windows, Linux, and Mac OS X, and study their implementation in regard to how they enumerate and map memory. We find that all of the analyzed programs use the operating system to perform these tasks, and further illustrate this by implementing an open source memory acquisition framework for Mac OS X. In a survey of kernel rootkit techniques, that prevent or filter physical memory access, we show that all 12 tested programs are vulnerable to anti-forensics, because they rely on the operating system for critical functions. To elliminate this vulnerability, we develop an operating system independent approach that directly utilizes the hardware to enumerate and map memory. By interacting with the PCI controller, we are able to safely avoid memory mapped device buffers while acquiring the entire physical address space. We program the page tables directly to map memory, forcing the MMU to facilitate arbitrary physical memory access from our driver’s data segment. We implement our techniques into the open source memory acquisition frameworks Winpmem, Pmem, and OSXPmem, furthering the capabilities of memory acquisition software on the Windows, Linux, and Mac OS X platforms. Finally, we apply our novel technique to related problems in memory forensics. Memory acquisition software for Linux can only be run on a system with the exact same kernel version and configuration as the system it was compiled on, due to dependencies on kernel data structures. We are able to create a minimal, kernel independent version of our module, which we inject into a compatible host module on the target. By hijacking the hosts data structures, we are able to load the infected module, redirect control flow, and communicate with it using a character device. A second innovative property of our acquisition approach is that, because we can enumerate the location of memory mapped device buffers, we are able to safely access memory regions unknown to the operating system. This allows us to acquire malicious firmware during of the memory acquisition process. We present a survey on firmware code and data in the physical address space, and show how we can capture the BIOS, PCI option ROMs, and the ACPI tables using our approach. We implement plugins for the open source memory analysis framework Volatility, which are able to extract the ACPI tables from memory and analyze them for malicious behavior.},
author = {Johannes Stüttgen},
}

@article{695bcb85c6ee0c01ba6fc377ad37b02a88f6a41b,
title = {Forensically Sound Data Acquisition in the Age of Anti-Forensic Innocence},
year = {2016},
url = {https://www.semanticscholar.org/paper/695bcb85c6ee0c01ba6fc377ad37b02a88f6a41b},
abstract = {In this thesis, we tackle anti-forensic and rootkit problems in digital forensics. An anti-forensic technique is any measure that prevents a forensic analysis or reduces its quality. First, we investigate the anti-forensic threat of hard drive firmware rootkits, which can prevent a forensic analyst from acquiring data from the hard drive, thus jeopardizing the forensic analysis. To this end, we first outline the threat of hard drive firmware rootkits. We then provide a procedure to detect and subvert already published hard disk drive firmware bootkits. We further outline potential avenues to detect hard drive firmware rootkits nested deeper within the hard disk drive’s so-called Service Area, a special storage on the magnetic platter reserved for use by the firmware. After addressing the acquisition of persistent data storage in form of hard disk drives, we shift towards acquisition and later analysis of volatile storage, in the form of RAM. To this end, we first evaluate the atomicity and integrity as well as anti-forensic resistance of different memory acquisition techniques with our novel black-box analysis technique. This black-box analysis technique in which memory contents are constantly changed via our payload application with a traceable access pattern, allows us to measure to which extent current memory acquisition methods satisfy atomicity and integrity when dumping the memory of processes. We also discuss their resistance against anti-forensics. As a result, we show that cold boot attacks belong to the most favorable memory acquisition techniques. We then investigate cold boot attacks in more detail. First, we experimentally confirm that cooling the RAM modules prolongs the remanence effect considerably. We then prove also experimentally that transplanting RAM modules from one system to another is possible. We further address the issue scrambling in modern DDR3 technology as well as other proposed countermeasures, such as BIOS passwords and temperature detection. We also show that once a system is cold-booted, malicious anti-forensic code running on the system stops running immediately and can thus no longer interfere with the memory acquisition. Therefore, we show the practical feasibility of cold boot attacks as anti-forensic resistant memory acquisition method. After outlining the anti-forensic resistant acquisition of evidence we address the analysis. To this end, we first revisited the theory of data analysis, especially the concept of essential data in forensic analysis as coined by Carrier in his seminal work “File System Forensic Analysis”. We first extend Carrier’s concept by differentiating different levels of essentiality. We introduce the notion of strictly essential data, which refers to data that is always required to be correct and non-manipulated by all systems to provide a specific functionality, and partially essential, which is only required to be correct and non-manipulated for some systems. We then practically verify both the original theories and our extensions in experiments. Eventually, we argue that essential data can help to build a trust hierarchy of data encountered during forensic analysis, from which we conclude that anti-forensic resistant analysis methods must only rely on what we call strictly essential, i.e., trusted, data, otherwise, the analysis is potentially impaired by anti-forensic measures because non-essential data can be freely manipulated without impacting the correct working of a system. Last but not least, we tackle a long unsolved problem in forensic memory analysis: Currently, all state-of-the-art digital forensic virtual memory analysis tools ignore unmapped memory pages, i.e., pages swapped out onto persistent storage. This can result in blind spots in which data and thus potential evidence is not analyzed. We fix this by analyzing the Windows NT virtual memory paging via a novel gray-box analysis method. To this end, we place traceable data into virtual memory and force it into both the physical RAM as well as the pagefile stored on persistent storage. We are thus able to reverse engineer the complete virtual address mapping, including the non-mapped pagefile. We evaluate our analysis results against real world data from Windows 7, 8, and 10 systems in both the 32 and 64-bit variants. By shedding light on this last blind spot of virtual memory analysis we increase its anti-forensic resistance, because we can now for the first time analyze the virtual address space in its entirety.},
author = {M. Gruhn},
}

@article{d3dcb45bbdbb440186a926b7541870d6c3844c72,
title = {A Survey on Digital Forensics Trends},
year = {2014},
url = {https://www.semanticscholar.org/paper/d3dcb45bbdbb440186a926b7541870d6c3844c72},
abstract = {1. ABSTRACT Digital forensic has evolved from addressing minor computer crimes to investigation of complex international cases with massive effect on the world. This paper studies the evolution of the digital forensic; its origins, its current position and its future directions. This paper sets the scene with exploring past literature on digital forensic approaches followed by the assessment and analysis of current state of art in both industrial and academic digital forensics research. The obtained results are compared and analyzed to provide a comprehensive view of the current digital forensics landscape. Furthermore, this paper highlights critical digital forensic issues that are being overlooked and not being addressed as deserved. The paper finally concludes with offering future research directions in this area.},
author = {A. Dehghantanha and Ramlan Mahmoud Mohsen Damshenas},
journal = {International Journal of Cyber-Security and Digital Forensics},
volume = {3},
pages = {209-234},
doi = {10.17781/P001347},
}

@article{9b52419d04c4d30f37940ee7c7fb7b75ae9c998a,
title = {Identifying the unknown in user space memory},
year = {2013},
url = {https://www.semanticscholar.org/paper/9b52419d04c4d30f37940ee7c7fb7b75ae9c998a},
abstract = {This thesis is a study of how the contents of volatile memory on the Windows operating system can be better understood and utilised for the purposes of digital forensic investigations. It proposes several techniques to improve the analysis of memory, with a focus on improving the detection of unknown code such as malware. These contributions allow the creation of a more complete reconstruction of the state of a computer at acquisition time, including whether or not the computer has been infected by malicious code.},
author = {A. White},
}

@article{1fc53056e0d26c260023dc55e518a295504062d0,
title = {An adaptive approach for Linux memory analysis based on kernel code reconstruction},
year = {2016},
url = {https://www.semanticscholar.org/paper/1fc53056e0d26c260023dc55e518a295504062d0},
abstract = {Memory forensics plays an important role in security and forensic investigations. Hence, numerous studies have investigated Windows memory forensics, and considerable progress has been made. In contrast, research on Linux memory forensics is relatively sparse, and the current knowledge does not meet the requirements of forensic investigators. Existing solutions are not especially sophisticated, and their complicated operation and limited treatment range are unsatisfactory. This paper describes an adaptive approach for Linux memory analysis that can automatically identify the kernel version and recovery symbol information from an image. In particular, given a memory image or a memory snapshot without any additional information, the proposed technique can automatically reconstruct the kernel code, identify the kernel version, recover symbol table files, and extract live system information. Experimental results indicate that our method runs satisfactorily across a wide range of operating system versions.},
author = {Shuhui Zhang and Xiangxu Meng and Lianhai Wang},
journal = {EURASIP Journal on Information Security},
volume = {2016},
pages = {1-13},
doi = {10.1186/S13635-016-0038-Z},
}

@article{7dbab82ed952e91b8ed5e7c6e72fa1e2b0e1a164,
title = {User Space Memory Analysis},
year = {2013},
url = {https://www.semanticscholar.org/paper/7dbab82ed952e91b8ed5e7c6e72fa1e2b0e1a164},
abstract = {},
author = {E. Smulders},
}
