@article{aa7a71165d8f125c1505791ba5440544eb03e2ae,
title = {Maat: Automatically Analyzing VirusTotal for Accurate Labeling and Effective Malware Detection},
year = {2020},
url = {https://www.semanticscholar.org/paper/aa7a71165d8f125c1505791ba5440544eb03e2ae},
abstract = {The malware analysis and detection research community relies on the online platform VirusTotal to label Android apps based on the scan results of around 60 antiviral scanners. Unfortunately, there are no standards on how to best interpret the scan results acquired from VirusTotal, which leads to the utilization of different threshold-based labeling strategies (e.g., if ten or more scanners deem an app malicious, it is considered malicious). While some of the utilized thresholds may be able to accurately approximate the ground truths of apps, the fact that VirusTotal changes the set and versions of the scanners it uses makes such thresholds unsustainable over time. We implemented a method, Maat, that tackles these issues of standardization and sustainability by automatically generating a Machine Learning (ML)-based labeling scheme, which outperforms threshold-based labeling strategies. Using the VirusTotal scan reports of 53K Android apps that span one year, we evaluated the applicability of Maat's ML-based labeling strategies by comparing their performance against threshold-based strategies. We found that such ML-based strategies (a) can accurately and consistently label apps based on their VirusTotal scan reports, and (b) contribute to training ML-based detection methods that are more effective at classifying out-of-sample apps than their threshold-based counterparts.},
author = {Aleieldin Salem and Sebastian Banescu and A. Pretschner},
doi = {10.1145/3465361},
arxivid = {2007.00510},
}

@article{ce3d91be0f29bc8198e419d5b6a67f7c35f7fb45,
title = {Poking the bear: lessons learned from probing three Android malware datasets},
year = {2018},
url = {https://www.semanticscholar.org/paper/ce3d91be0f29bc8198e419d5b6a67f7c35f7fb45},
abstract = {To counter the continuous threat posed by Android malware, we attempted to devise a novel method based on active learning. Nonetheless, evaluating our active learning based method on three different Android malware datasets resulted in performance discrepancies. In an attempt to explain such inconsistencies, we postulated research questions and designed corresponding experiments to answer them. The results of our experiments unveiled the reasons behind the struggles of our method and, more importantly, revealed some limitations with the current Android malware detection methods that, we fear, can be leveraged by malware authors to evade detection. In this paper, we share with the research community our research questions, experiments, and findings to instigate researchers to devise methods to tackle such limitations.},
author = {Aleieldin Salem and A. Pretschner},
journal = {Proceedings of the 1st International Workshop on Advances in Mobile App Analysis},
volume = {},
pages = {},
doi = {10.1145/3243218.3243222},
}

@article{9a4a5302499c7faf51c2888635336854c74ebe91,
title = {Empirical study of malware diversity in major Android markets},
year = {2018},
url = {https://www.semanticscholar.org/paper/9a4a5302499c7faf51c2888635336854c74ebe91},
abstract = {ABSTRACT The popularity of Android has motivated a significant increase in the amount of malware specially designed to target this operating system. During the last years, the threat has become more serious and every day cybercriminals create and share new specimens through almost all existing markets. This situation has promoted a notable research interest in the development of automated malware detection and classification systems. In this paper, we perform a large-scale empirical study to examine the diversity of Android malware in major markets. Through the analysis of more than 5 million of apps, we use the labels assigned by 57 different anti-malware vendors and diversity measures to get insights about the distribution and evolution of Android malware. Furthermore, we propose a dissimilarity measure for comparing these labels, which can be applied as part of an agglomerative hierarchical clustering algorithm. This clustering method groups the labels according to the scanning reports of different anti-malware vendors. The results obtained make evident an increase in the diversification of malware in both official and alternative markets. Moreover, we show how the criteria of various anti-malware, in conjunction with clustering techniques, is a suitable approach for grouping and analysing malware samples that perform a similar behaviour.},
author = {César Soto-Valero and Mabel González},
journal = {Journal of Cyber Security Technology},
volume = {2},
pages = {51 - 74},
doi = {10.1080/23742917.2018.1483876},
}

@article{484bc4621cb23385e356019bf54e4ea9291114f5,
title = {Don't Pick the Cherry: An Evaluation Methodology for Android Malware Detection Methods},
year = {2019},
url = {https://www.semanticscholar.org/paper/484bc4621cb23385e356019bf54e4ea9291114f5},
abstract = {In evaluating detection methods, the malware research community relies on scan results obtained from online platforms such as VirusTotal. Nevertheless, given the lack of standards on how to interpret the obtained data to label apps, researchers hinge on their intuitions and adopt different labeling schemes. The dynamicity of VirusTotal's results along with adoption of different labeling schemes significantly affect the accuracies achieved by any given detection method even on the same dataset, which gives subjective views on the method's performance and hinders the comparison of different malware detection techniques. 
In this paper, we demonstrate the effect of varying (1) time, (2) labeling schemes, and (3) attack scenarios on the performance of an ensemble of Android repackaged malware detection methods, called dejavu, using over 30,000 real-world Android apps. Our results vividly show the impact of varying the aforementioned 3 dimensions on dejavu's performance. With such results, we encourage the adoption of a standard methodology that takes into account those 3 dimensions in evaluating newly-devised methods to detect Android (repackaged) malware.},
author = {Aleieldin Salem and Sebastian Banescu and A. Pretschner},
journal = {ArXiv},
volume = {abs/1903.10560},
pages = {},
arxivid = {1903.10560},
}

@article{66bc9c97757bd9a83d84d0e4bab1ffaf59add7ec,
title = {Machine-Learning based analysis and classification of Android malware signatures},
year = {2019},
url = {https://www.semanticscholar.org/paper/66bc9c97757bd9a83d84d0e4bab1ffaf59add7ec},
abstract = {Abstract Multi-scanner Antivirus (AV) systems are often used for detecting Android malware since the same piece of software can be checked against multiple different AV engines. However, in many cases the same software application is flagged as malware by few AV engines, and often the signatures provided contradict each other, showing a clear lack of consensus between different AV engines. This work analyzes more than 80 thousand Android applications flagged as malware by at least one AV engine, with a total of almost 260 thousand malware signatures. In the analysis, we identify 41 different malware families, we study their relationships and the relationships between the AV engines involved in such detections, showing that most malware cases belong to either Adware abuse or really dangerous Harmful applications, but some others are unspecified (or Unknown). With the help of Machine Learning and Graph Community Algorithms, we can further combine the different AV detections to classify such Unknown apps into either Adware or Harmful risks, reaching F1-score above 0.84.},
author = {I. Martín and José Alberto Hernández and Sergio de los Santos},
journal = {Future Gener. Comput. Syst.},
volume = {97},
pages = {295-305},
doi = {10.1016/J.FUTURE.2019.03.006},
}

@article{f0239e5b818f1d9b07b2e6812ae7c6f3adb70b5c,
title = {Maximizing accuracy in multi-scanner malware detection systems},
year = {2020},
url = {https://www.semanticscholar.org/paper/f0239e5b818f1d9b07b2e6812ae7c6f3adb70b5c},
abstract = {Abstract A variety of anti-malware scanners have been developed for malware detection. Previous research has indicated that combining multiple different scanners can achieve better result compared to any single scanner. However, given the diversity in detection rates and accuracy of different anti-malware scanners, how to determine the best possible outcome of multi-scanner systems in terms of accuracy and how to achieve this best outcome remain formidable tasks. In this paper, we propose three models to capture the combined output of different combinations of anti-malware scanners based on the limited amount of historical information available. These models enable us to predict the accuracy level of each combination, which helps us to determine the optimal configuration of the multi-scanner detection system to achieve maximum accuracy. We also introduce two methods to identify a near-optimal subset of scanners that can help reduce scanning cost while under time constraint. From simulations over randomly generated hypothetical datasets and experiments conducted with real world malware and goodware datasets and anti-virus scanners, we found that our models perform well in predicting the optimal configuration and can achieve an accuracy as high as within 1% of true maximum.},
author = {M. N. Sakib and Chin-Tser Huang and Ying-Dar Lin},
journal = {Comput. Networks},
volume = {169},
pages = {107027},
doi = {10.1016/j.comnet.2019.107027},
}

@article{6ef3b5a0af396e42711aab8ffbfb1728c2cb95b2,
title = {AV-Meter: An Evaluation of Antivirus Scans and Labels},
year = {2014},
url = {https://www.semanticscholar.org/paper/6ef3b5a0af396e42711aab8ffbfb1728c2cb95b2},
abstract = {Antivirus scanners are designed to detect malware and, to a lesser extent, to label detections based on a family association. The labeling provided by AV vendors has many applications such as guiding efforts of disinfection and countermeasures, intelligence gathering, and attack attribution, among others. Furthermore, researchers rely on AV labels to establish a baseline of ground truth to compare their detection and classification algorithms. This is done despite many papers pointing out the subtle problem of relying on AV labels. However, the literature lacks any systematic study on validating the performance of antivirus scanners, and the reliability of those labels or detection.},
author = {Aziz Mohaisen and Omar Alrawi},
doi = {10.1007/978-3-319-08509-8_7},
}

@article{c58e3b32bc88ed3d8e7bcdf0523eb27057bd7d0f,
title = {Deep Ground Truth Analysis of Current Android Malware},
year = {2017},
url = {https://www.semanticscholar.org/paper/c58e3b32bc88ed3d8e7bcdf0523eb27057bd7d0f},
abstract = {To build effective malware analysis techniques and to evaluate new detection tools, up-to-date datasets reflecting the current Android malware landscape are essential. For such datasets to be maximally useful, they need to contain reliable and complete information on malware’s behaviors and techniques used in the malicious activities. Such a dataset shall also provide a comprehensive coverage of a large number of types of malware. The Android Malware Genome created circa 2011 has been the only well-labeled and widely studied dataset the research community had easy access to (As of 12/21/2015 the Genome authors have stopped supporting the dataset sharing due to resource limitation). But not only is it outdated and no longer represents the current Android malware landscape, it also does not provide as detailed information on malware’s behaviors as needed for research. Thus it is urgent to create a high-quality dataset for Android malware. While existing information sources such as VirusTotal are useful, to obtain the accurate and detailed information for malware behaviors, deep manual analysis is indispensable. In this work we present our approach to preparing a large Android malware dataset for the research community. We leverage existing anti-virus scan results and automation techniques in categorizing our large dataset (containing 24,650 malware app samples) into 135 varieties (based on malware behavioral semantics) which belong to 71 malware families. For each variety, we select three samples as representatives, for a total of 405 malware samples, to conduct in-depth manual analysis. Based on the manual analysis result we generate detailed descriptions of each malware variety’s behaviors and include them in our dataset. We also report our observations on the current landscape of Android malware as depicted in the dataset. Furthermore, we present detailed documentation of the process used in creating the dataset, including the guidelines for the manual analysis. We make our Android malware dataset available to the research community.},
author = {Fengguo Wei and Yuping Li and Sankardas Roy and Xinming Ou and Wu Zhou},
doi = {10.1007/978-3-319-60876-1_12},
}

@article{68b1fbd44691e4ad754092e7d5fde6f6775daca9,
title = {POSTER: Enabling Fair ML Evaluations for Security},
year = {2018},
url = {https://semanticscholar.org/paper/68b1fbd44691e4ad754092e7d5fde6f6775daca9},
abstract = {Machine learning is widely used in security research to classify malicious activity, ranging frommalware tomalicious URLs and network traffic. However, published performance numbers often seem to leave little room for improvement and, due to a wide range of datasets and configurations, cannot be used to directly compare alternative approaches; moreover, most evaluations have been found to suffer from experimental bias which positively inflates results. In this manuscript we discuss the implementation of Tesseract, an open-source tool to evaluate the performance of machine learning classifiers in a security setting mimicking a deployment with typical data feeds over an extended period of time. In particular, Tesseract allows for a fair comparison of different classifiers in a realistic scenario, without disadvantaging any given classifier. Tesseract is available as open-source to provide the academic community with a way to report sound and comparable performance results, but also to help practitioners decide which system to deploy under specific budget constraints.},
author = {Feargus  Pendlebury and Fabio  Pierazzi and Roberto  Jordaney and Johannes  Kinder and Lorenzo  Cavallaro},
journal = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
volume = {},
pages = {},
doi = {10.1145/3243734.3278505},
}

@article{d5f7048224f507101a57f37c477d2c5009622879,
title = {NLabel: An Accurate Familial Clustering Framework for Large-scale Weakly-labeled Malware},
year = {2020},
url = {https://www.semanticscholar.org/paper/d5f7048224f507101a57f37c477d2c5009622879},
abstract = {Automatic family labeling for malware is in demand, especially for today's malware scale. While business Anti-Virus engines provide an efficient family labeling method, the raw labels tend to be inconsistent. Prior works mitigate such inconsistency by detecting the aliases and majority voting to obtain the final family label. However, these methods solve the inconsistency in a coarse-grained and vulnerable manner, and the obtained family label is inaccurate sometimes. In this work, we propose NLabel to conduct familial clustering based on AV engines' raw labels. On the one hand, NLabel uses word embedding techniques to capture the similarity among raw labels, transform the inconsistent labels of the same family into similar semantic representations, and mitigate the inconsistency at finer granularity. On the other hand, we propose a hierarchical family clustering method to boost the performance of large-scale data sets. Experimental results show that our method outperforms the SOTA.},
author = {Yannan Liu and Yabin Lai and Kaizhi Wei and Liang Gu and Zhengzheng Yan},
journal = {2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
volume = {},
pages = {210-216},
doi = {10.1109/TrustCom50675.2020.00039},
}

@article{34dd06c5b82096de3d93c094b91f668d1ea1aac9,
title = {AndrEnsemble: Leveraging API Ensembles to Characterize Android Malware Families},
year = {2019},
url = {https://www.semanticscholar.org/paper/34dd06c5b82096de3d93c094b91f668d1ea1aac9},
abstract = {Assigning family labels to malicious apps is a common practice for grouping together malware with identical behavior. However, recent studies show that apps labeled as belonging to the same family do not necessarily behave similarly: one app may lack or have extra capabilities compared to others in the same family, and, conversely, two apps labeled as belonging to different families may exhibit close behavior. To reveal these inconsistencies, this paper presents AndrEnsemble, a characterization system for Android malware families based on ensembles of sensitive API calls extracted from aggregated call graphs of different families. Our method has several advantages over similar characterization approaches, including a greater reduction ratio with respect to original call graphs, robustness against transformation attacks, and flexibility to be applied at different granularity levels. We experimentally validate our approach and discuss three specific use cases: mobile ransomware, SMS Trojans and banking Trojans. This left us with some interesting findings. First of all, malicious operations in these types of malware are not necessarily exercised by using several sensitive API calls all together. Second, SMS Trojans have larger ensembles of API calls compared to the other types. Last but not least, we identified several samples with identical ensembles though being labeled as part of different families.},
author = {Omid Mirzaei and Guillermo Suarez-Tangil and J. M. D. Fuentes and Juan E. Tapiador and G. Stringhini},
journal = {Proceedings of the 2019 ACM Asia Conference on Computer and Communications Security},
volume = {},
pages = {},
doi = {10.1145/3321705.3329854},
}

@article{817ccac6fb23b67487b067cd4b15404f517f93b8,
title = {AVclass2: Massive Malware Tag Extraction from AV Labels},
year = {2020},
url = {https://www.semanticscholar.org/paper/1045f411143708ecbfbbc7e4f26af58ba7715638},
abstract = {Tags can be used by malware repositories and analysis services to enable searches for samples of interest across different dimensions. Automatically extracting tags from AV labels is an efficient approach to categorize and index massive amounts of samples. Recent tools like AVclass and Euphony have demonstrated that, despite their noisy nature, it is possible to extract family names from AV labels. However, beyond the family name, AV labels contain much valuable information such as malware classes, file properties, and behaviors. This work presents AVclass2, an automatic malware tagging tool that given the AV labels for a potentially massive number of samples, extracts clean tags that categorize the samples. AVclass2 uses, and helps building, an open taxonomy that organizes concepts in AV labels, but is not constrained to a predefined set of tags. To keep itself updated as AV vendors introduce new tags, it provides an update module that automatically identifies new taxonomy entries, as well as tagging and expansion rules that capture relations between tags. We have evaluated AVclass2 on 42M samples and showed how it enables advanced malware searches and to maintain an updated knowledge base of malware concepts in AV labels.},
author = {Silvia Sebasti'an and Juan Caballero},
journal = {Annual Computer Security Applications Conference},
volume = {},
pages = {},
doi = {10.1145/3427228.3427261},
arxivid = {2006.10615},
}

@article{ed67b98fb5654b3799668894bf57ebcda234f994,
title = {Building a Framework for Objective Evaluation of Malware Detection Methods},
year = {2019},
url = {https://www.semanticscholar.org/paper/ed67b98fb5654b3799668894bf57ebcda234f994},
abstract = {Context The research community has been working towards devising methods to detect Android malware (e.g., [7, 10, 13, 15]). Despite proving to be sometimes inconsistent [4], researchers continue to rely on VirusTotal [16] to either download training data to evaluate their newly-devised methods [14, 17, 19], or to label the apps they manually gathered from the wild (e.g., app marketplaces) [1, 6, 18], due to the lack of better, more feasible alternatives.},
author = {},
}

@article{17891663455cfd1bfef64e51ce3a77c45b0ec530,
title = {Tools for the Detection and Analysis of Potentially Unwanted Programs},
year = {2018},
url = {https://www.semanticscholar.org/paper/17891663455cfd1bfef64e51ce3a77c45b0ec530},
abstract = {Esta tesis estudia los programas potencialmente no deseados (PUP), una categoria de software que, aunque no totalmente malignos, presentan comportamientos que pueden alterar la seguridad o la privacidad de los sistemas en que se instalan. El PUP suele venir empaquetado con freeware, i.e., software propietario que puede usarse sin coste. Un vector popular de distribucion del freeware son los portales de descargas, i.e., sitios web que indexan, clasifican y alojan programas. Los portales de descargas pueden ser abusados para distribuir PUP. El freeware suele distribuirse como un instalador, i.e., un programa auxiliar encargado de realizar todos los pasos necesarios para instalar otro programa. Durante la instalacion, ademas de instalar el programa deseado por el usuario, el instalador puede tambien instalar PUP. El PUP puede ser dificil de desinstalar y puede permanecer en el sistema despues de que el usuario intente desinstalarlo. Los sistemas actuales de analisis de malware no son capaces de detectar comportamientos caracteristicos del PUP. Por ejemplo estos sistemas operan sobre una sola ejecucion de un programa, mientras que la deteccion del PUP suele requerir analizar juntas dos ejecuciones: la instalacion y la desintalacion. Esta tesis presenta nuevas tecnicas para detectar y analizar PUP y contiene tres contribuciones principales. Primero, se presenta un estudio de la prevalencia de PUP y malware en portales de descargas, exponiendo los comportamientos abusivos que utilizan sus autores. Segundo, se propone un sistema especialmente disenado para identificar dinamicamente comportamientos de PUP durante la instalacion y desintalacion. Tercero, se describe AVCLASS, una herramienta automatica de etiquetado, que dada las etiquetas asignadas por los antivirus (AV) a un numero potencialmente masivo de muestras, identifica el nombre de familia mas probable para cada muestra. Para analizar la distribucion de PUP a traves de los portales de descargas construimos una plataforma y la usamos para descargar 191K instaladores de freeware para Windows desde 20 portales. Analizando los instaladores medimos una proporcion global de PUP y malware entre 8% (estimacion conservadora) y 26% (estimacion laxa). En 18 de los 20 portales examinados, la cantidad es inferior al 9%. Pero, tambien encontramos dos portales utilizados exclusivamente para distribuir PUP. Ademas, detallamos los diferentes comportamientos abusivos utilizados por los autores del PUP. A continuacion, presentamos una plataforma para analizar dinamicamente instaladores. Nuestra plataforma ejecuta el instalador, lo navega para completar la instalacion, analiza la instalacion identificando comportamientos de PUP, identifica la lista de programas instalados, revisa si cada programa instalado tiene un desinstalador, ejecuta los desinstaladores, analiza la desintalacion identificando comportamientos de PUP, y compara la instalacion y desinstalacion determinando si todos los programas se desinstalaron completamente. Finalmente, describimos AVCLASS, una herramienta automatica para etiquetar ejecutables maliciosos como variantes de familias conocidas. AVCLASS toma como entrada etiquetas asignadas por los AV de un numero de muestras potencialmente masivo, e identifica la familia mas probable para cada muestra. Aunque las etiquetas que asignan los AV suelen ser inconsistentes, a menudo no hay otra informacion disponible para el etiquetado. AVCLASS implementa novedosas tecnicas automaticas para abordar tres desafios debidos a la inconsistencia de las etiquetas de los AV: normalizacion, eliminacion de tokens genericos y deteccion de alias. Hemos evaluado AVCLASS en 10 datasets con 8,9M de muestras. AVCLASS alcanza una medida F1 de hasta 93.9 en datasets etiquetados y asigna nombres de familia comunmente utilizados por los AV. Hemos puesto AVCLASS a disposicion de la comunidad. ----------ABSTRACT---------- In this thesis we study potentially unwanted programs (PUP), a category of undesirable software that, while not outright malicious, contains behaviors that may alter the security state or the privacy of the system on which they are installed. PUP often comes bundled with freeware, i.e., proprietary software that can be used free of charge. A popular vector for distributing freeware are download portals, i.e., websites that index, categorize, and host programs. Download portals can be abused to distribute PUP. Freeware is often distributed as an installer, i.e., an auxiliary program in charge of performing all installation steps for the target program. During installation, besides the target program desired by the user, the installer may install PUP as well. PUP may be difficult to uninstall and may persist installed in the system after the user tries to uninstall it. Current malware analysis systems are not able to detect and analyze characteristic behaviors of PUP. For example, current malware analysis systems operate on a single program execution, while detecting incomplete PUP uninstallations requires analyzing together two program executions: the installation and the uninstallation. This thesis presents novel tools to detect and analyze potentially unwanted programs. More concretely, it describes three main contributions. First, it presents a measurement study of PUP prevalence in download portals, exposing the abusive behaviors that authors of malicious software use to distribute their applications through download portals. Second, it proposes a system especially designed to dynamically detect and analyze PUP behaviors during program installation and uninstallation. Third, it describes AVCLASS, an automatic labeling tool that given the AV labels for a potentially massive number of samples, outputs the most likely family for each sample. To analyze the distribution of PUP through download portals, we build a platform to crawl download portals and apply it to download 191KWindows freeware installers from 20 download portals. We analyze the collected installers measuring an overall ratio of PUP and malware between 8% (conservative estimate) and 26% (lax estimate). In 18 of the 20 download portals examined the amount of PUP and malware is below 9%. But, we also find two download portals exclusively used to distribute PPI downloaders. We also detail different abusive behaviors that authors of undesirable programs use to distribute their programs through download portals. We present a platform to perform dynamic behavioral analysis of an input installer. Our platform executes the installer, navigates it to complete a successful installation, analyzes the installation to identify PUP behaviors, identifies the list of installed programs regardless of the installation location, checks whether each installed program has a corresponding uninstaller, executes the uninstallers, analyzes the uninstallation to identify PUP behaviors, and correlates the installation and uninstallation executions to determine if all installed programs were completely uninstalled. Finally, we describe AVCLASS, a tool for automatically labeling malicious executables as variants of known families. AVCLASS takes as input the AV labels for a potentially massive number of samples and outputs the most likely family names for each sample. While AV labels are well-known to be inconsistent, there is often no other information available for labeling. AVCLASS implements novel automatic techniques to address 3 key challenges due to AV labels inconsistencies: normalization, removal of generic tokens, and alias detection. We have evaluated AVCLASS on 10 datasets comprising 8.9 M samples. AVCLASS’s achieves F1 measures up to 93.9 on labeled datasets and samples are labeled with fine-grained family names commonly used by the AV vendors. We have released AVCLASS to the community.},
author = {Richard Rivera Guevara},
doi = {10.20868/upm.thesis.53395},
}

@article{1e68c2843048e24e463928e94f67cbf3c8fd6503,
title = {Towards Accurate Labeling of Android Apps for Reliable Malware Detection},
year = {2020},
url = {https://www.semanticscholar.org/paper/1e68c2843048e24e463928e94f67cbf3c8fd6503},
abstract = {In training their newly-developed malware detection methods, researchers rely on threshold-based labeling strategies that interpret the scan reports provided by online platforms, such as VirusTotal. The dynamicity of this platform renders those labeling strategies unsustainable over prolonged periods, which leads to inaccurate labels. Using inaccurately labeled apps to train and evaluate malware detection methods significantly undermines the reliability of their results, leading to either dismissing otherwise promising detection approaches or adopting intrinsically inadequate ones. The infeasibility of generating accurate labels via manual analysis and the lack of reliable alternatives force researchers to utilize VirusTotal to label apps. In the paper, we tackle this issue in two manners. Firstly, we reveal the aspects of VirusTotalss dynamicity and how they impact threshold-based labeling strategies and provide actionable insights on how to use these labeling strategies given VirusTotal's dynamicity reliably. Secondly, we motivate the implementation of alternative platforms by (a) identifying VirusTotal limitations that such platforms should avoid, and (b) proposing an architecture of how such platforms can be constructed to mitigate VirusTotal's limitations.},
author = {Aleieldin Salem},
journal = {Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
volume = {},
pages = {},
doi = {10.1145/3422337.3447849},
arxivid = {2007.00464},
}

@article{0331eb7eab48278331189cb5e68e22d68860871b,
title = {Looking Back on Three Years of Flash-based Malware},
year = {2017},
url = {https://www.semanticscholar.org/paper/0331eb7eab48278331189cb5e68e22d68860871b},
abstract = {Adobe Flash is about to be replaced by alternative technologies, yet Flash-based malware appears to be more common then ever. In this paper we inspect the properties and temporal distribution of this class of malware over a period of three consecutive years and 2.3 million unique Flash animations. In particular, we focus on initially undetected malware and thus look at a subset for which traditional methods have failed to provide timely detection. We analyze the prevalence of these samples and characterize their nature.},
author = {Christian Wressnegger and K. Rieck},
journal = {Proceedings of the 10th European Workshop on Systems Security},
volume = {},
pages = {},
doi = {10.1145/3065913.3065921},
}

@article{1e2681da9bed9abc8f47cd0d3834cb8d820a63b8,
title = {On the Lack of Consensus in Anti-Virus Decisions: Metrics and Insights on Building Ground Truths of Android Malware},
year = {2016},
url = {https://www.semanticscholar.org/paper/1e2681da9bed9abc8f47cd0d3834cb8d820a63b8},
abstract = {There is generally a lack of consensus in Antivirus AV engines' decisions on a given sample. This challenges the building of authoritative ground-truth datasets. Instead, researchers and practitioners may rely on unvalidated approaches to build their ground truth, e.g., by considering decisions from a selected set of Antivirus vendors or by setting up a threshold number of positive detections before classifying a sample. Both approaches are biased as they implicitly either decide on ranking AV products, or they consider that all AV decisions have equal weights. In this paper, we extensively investigate the lack of agreement among AV engines. To that end, we propose a set of metrics that quantitatively describe the different dimensions of this lack of consensus. We show how our metrics can bring important insights by using the detection results of 66 AV products on 2 million Android apps as a case study. Our analysis focuses not only on AV binary decision but also on the notoriously hard problem of labels that AVs associate with suspicious files, and allows to highlight biases hidden in the collection of a malware ground truth--a foundation stone of any malware detection approach.},
author = {M. Hurier and Kevin Allix and Tegawendé F. Bissyandé and Jacques Klein and Y. L. Traon},
doi = {10.1007/978-3-319-40667-1_8},
}

@article{036238da0d080608a865d8cc209e4c067b02abd2,
title = {TagVet: Vetting Malware Tags using Explainable Machine Learning},
year = {2021},
url = {https://www.semanticscholar.org/paper/036238da0d080608a865d8cc209e4c067b02abd2},
abstract = {When managing large malware collections, it is common practice to use short tags for grouping and organizing samples. For example, collected malware is often tagged according to its origin, family, functionality, or clustering. While these simple tags are essential for keeping abreast of the rapid malware development, they can become disconnected from the actual behavior of the samples and, in the worst case, mislead the analyst. In particular, if tags are automatically assigned, it is often unclear whether they indeed align with the malware functionality. In this paper, we propose a method for vetting tags in malware collections. Our method builds on recent techniques of explainable machine learning, which enable us to automatically link tags to behavioral patterns observed during dynamic analysis. To this end, we train a neural network to classify different tags and trace back its decision to individual system calls and arguments. We empirically evaluate our method on tags for malware functionality, families, and clusterings. Our results demonstrate the utility of this approach and pinpoint interesting relations of malware tags in practice.},
author = {Lukas Pirch and Alexander Warnecke and Christian Wressnegger and K. Rieck},
journal = {Proceedings of the 14th European Workshop on Systems Security},
volume = {},
pages = {},
doi = {10.1145/3447852.3458719},
}

@article{20ef2c08ef2de8a0854fa9087d0b1380b9780b62,
title = {Evasion Is Not Enough: A Case Study of Android Malware},
year = {2020},
url = {https://www.semanticscholar.org/paper/20ef2c08ef2de8a0854fa9087d0b1380b9780b62},
abstract = {A growing number of Android malware detection systems are based on Machine Learning (ML) methods. However, ML methods are often vulnerable to evasion attacks, in which an adversary manipulates malicious instances so they are classified as benign. Here, we present a novel evaluation scheme for evasion attack generation that exploits the weak spots of known Android malware detection systems. We implement an innovative evasion attack on Drebin [3]. After our novel evasion attack, Drebin’s detection rate decreased by 12%. However, when inspecting the functionality and maliciousness of the manipulated instances, the maliciousness rate increased, whereas the functionality rate decreased by 72%. We show that non-functional apps, do not constitute a threat to users and are thus useless from an attacker’s point of view. Hence, future evaluations of attacks against Android malware detection systems should also address functionality and maliciousness tests.},
author = {Harel Berger and C. Hajaj and A. Dvir},
doi = {10.1007/978-3-030-49785-9_11},
}

@article{3a443ab720f73ae72f44ca54b6ef30648c543b3a,
title = {Measuring and Modeling the Label Dynamics of Online Anti-Malware Engines},
year = {2020},
url = {https://www.semanticscholar.org/paper/3a443ab720f73ae72f44ca54b6ef30648c543b3a},
abstract = {VirusTotal provides malware labels from a large set of antimalware engines, and is heavily used by researchers for malware annotation and system evaluation. Since different engines often disagree with each other, researchers have used various methods to aggregate their labels. In this paper, we take a data-driven approach to categorize, reason, and validate common labeling methods used by researchers. We first survey 115 academic papers that use VirusTotal, and identify common methodologies. Then we collect the daily snapshots of VirusTotal labels for more than 14,000 files (including a subset of manually verified ground-truth) from 65 VirusTotal engines over a year. Our analysis validates the benefits of threshold-based label aggregation in stabilizing files’ labels, and also points out the impact of poorly-chosen thresholds. We show that hand-picked “trusted” engines do not always perform well, and certain groups of engines are strongly correlated and should not be treated independently. Finally, we empirically show certain engines fail to perform in-depth analysis on submitted files and can easily produce false positives. Based on our findings, we offer suggestions for future usage of VirusTotal for data annotation.},
author = {Shuofei Zhu and J. Shi and Limin Yang and Boqin Qin and Ziyi Zhang and Linhai Song and Gang Wang},
}

@article{f73bf84e00455987f12b1f523f0b83769fe7131c,
title = {Euphony: Harmonious Unification of Cacophonous Anti-Virus Vendor Labels for Android Malware},
year = {2017},
url = {https://www.semanticscholar.org/paper/f73bf84e00455987f12b1f523f0b83769fe7131c},
abstract = {Android malware is now pervasive and evolving rapidly. Thousands of malware samples are discovered every day with new models of attacks. The growth of these threats has come hand in hand with the proliferation of collective repositories sharing the latest specimens. Having access to a large number of samples opens new research directions aiming at efficiently vetting apps. However, automatically inferring a reference ground-truth from those repositories is not straightforward and can inadvertently lead to unforeseen misconceptions. On the one hand, samples are often mis-labeled as different parties use distinct naming schemes for the same sample. On the other hand, samples are frequently mis-classified due to conceptual errors made during labeling processes. In this paper, we analyze the associations between all labels given by different vendors and we propose a system called EUPHONY to systematically unify common samples into family groups. The key novelty of our approach is that no a-priori knowledge on malware families is needed. We evaluate our approach using reference datasets and more than 0.4 million additional samples outside of these datasets. Results show that EUPHONY provides competitive performance against the state-of-the-art.},
author = {M. Hurier and Guillermo Suarez-Tangil and S. K. Dash and Tegawendé F. Bissyandé and Y. L. Traon and Jacques Klein and L. Cavallaro},
journal = {2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)},
volume = {},
pages = {425-435},
doi = {10.1109/MSR.2017.57},
}

@article{c2ccba662b84f559a63d3110f2a5a1d7c351884b,
title = {INFERRING MALWARE DETECTOR METRICS IN THE ABSENCE OF GROUND-TRUTH},
year = {2021},
url = {https://www.semanticscholar.org/paper/c2ccba662b84f559a63d3110f2a5a1d7c351884b},
abstract = {. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi Chapter 1: Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.1 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Summary of Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3 Organization of the Dissertation . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Chapter 2: Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.1 Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.1.1 Threshold Voting and Expert Selection . . . . . . . . . . . . . . . . . . . 8 2.2 Known Ground-Truth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.3 Statistical Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.4 Algorithmic Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 Chapter 3: Measuring Relative Accuracy of Malware Detectors in the Absence of GroundTruth∗ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3.1 Chapter Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3.2 Problem Statement and Methodology . . . . . . . . . . . . . . . . . . . . . . . . 11 3.2.1 Definitions of Relative Accuracy of Malware Detectors . . . . . . . . . . . 11 3.2.2 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3.3 Experiments and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 3.3.1 Experiments with Synthetic Data . . . . . . . . . . . . . . . . . . . . . . . 15},
author = {John Charlton},
}

@article{6b6299f3e6f0d0f24ba6536d3d6fabc36738765c,
title = {Comparing Stimulation Techniques for Detecting Android},
year = {2017},
url = {https://www.semanticscholar.org/paper/6b6299f3e6f0d0f24ba6536d3d6fabc36738765c},
abstract = {Context Android dominates the handheld devices market with more than 80% marketshare. Needless to say, such popularity encourages malware authors to write and distribute malicious applications (hereafter apps) that target Android devices. To smoothen the spread of their malicious apps, malware authors tend to design their instances to mimick the appearance and behavior of benign apps (e.g., games), effectively tricking users into voluntarily installing malicious apps on their own devices. This model resembles that of Trojan horses, which have been distributed and studied for decades on various platforms.},
author = {Piggybacked Malware},
}

@article{dcdb1e4191d6dfc5b4b6281dafbadb84c17267c6,
title = {Stimulation and Detection of Android Repackaged Malware with Active Learning},
year = {2018},
url = {https://www.semanticscholar.org/paper/dcdb1e4191d6dfc5b4b6281dafbadb84c17267c6},
abstract = {Repackaging is a technique that has been increasingly adopted by authors of Android malware. The main problem facing the research community working on devising techniques to detect this breed of malware is the lack of ground truth that pinpoints the malicious segments grafted within benign apps. Without this crucial knowledge, it is difficult to train reliable classifiers able to effectively classify novel, out-of-sample repackaged malware. To circumvent this problem, we argue that reliable classifiers can be trained to detect repackaged malware, if they are allowed to request new, more accurate representations of an app's behavior. This learning technique is referred to as active learning. 
In this paper, we propose the usage of active learning to train classifiers able to cope with the ambiguous nature of repackaged malware. We implemented an architecture, Aion, that connects the processes of stimulating and detecting repackaged malware using a feedback loop depicting active learning. Our evaluation of a sample implementation of Aion using two malware datasets (Malgenome and Piggybacking) shows that active learning can outperform conventional detection techniques and, hence, has great potential to detect Android repackaged malware.},
author = {Aleieldin Salem},
journal = {ArXiv},
volume = {abs/1808.01186},
pages = {},
arxivid = {1808.01186},
}

@article{a271104f11868bbc07b7599cdede28d866e63e9b,
title = {VAMO: towards a fully automated malware clustering validity analysis},
year = {2012},
url = {https://www.semanticscholar.org/paper/a271104f11868bbc07b7599cdede28d866e63e9b},
abstract = {Malware clustering is commonly applied by malware analysts to cope with the increasingly growing number of distinct malware variants collected every day from the Internet. While malware clustering systems can be useful for a variety of applications, assessing the quality of their results is intrinsically hard. In fact, clustering can be viewed as an unsupervised learning process over a dataset for which the complete ground truth is usually not available. Previous studies propose to evaluate malware clustering results by leveraging the labels assigned to the malware samples by multiple anti-virus scanners (AVs). However, the methods proposed thus far require a (semi-)manual adjustment and mapping between labels generated by different AVs, and are limited to selecting a reference sub-set of samples for which an agreement regarding their labels can be reached across a majority of AVs. This approach may bias the reference set towards "easy to cluster" malware samples, thus potentially resulting in an overoptimistic estimate of the accuracy of the malware clustering results.
 In this paper we propose VAMO, a system that provides a fully automated quantitative analysis of the validity of malware clustering results. Unlike previous work, VAMO does not seek a majority voting-based consensus across different AV labels, and does not discard the malware samples for which such a consensus cannot be reached. Rather, VAMO explicitly deals with the inconsistencies typical of multiple AV labels to build a more representative reference set, compared to majority voting-based approaches. Furthermore, VAMO avoids the need of a (semi-)manual mapping between AV labels from different scanners that was required in previous work. Through an extensive evaluation in a controlled setting and a real-world application, we show that VAMO outperforms majority voting-based approaches, and provides a better way for malware analysts to automatically assess the quality of their malware clustering results.},
author = {R. Perdisci and U. ManChon},
doi = {10.1145/2420950.2420999},
}

@article{c284db823f7fd79444c6cf378949201479311789,
title = {Eight Years of Rider Measurement in the Android Malware Ecosystem: Evolution and Lessons Learned},
year = {2018},
url = {https://www.semanticscholar.org/paper/c284db823f7fd79444c6cf378949201479311789},
abstract = {Despite the growing threat posed by Android malware, the research community is still lacking a comprehensive view of common behaviors and trends exposed by malware families active on the platform. Without such view, the researchers incur the risk of developing systems that only detect outdated threats, missing the most recent ones. In this paper, we conduct the largest measurement of Android malware behavior to date, analyzing over 1.2 million malware samples that belong to 1.2K families over a period of eight years (from 2010 to 2017). We aim at understanding how the behavior of Android malware has evolved over time, focusing on repackaging malware. In this type of threats different innocuous apps are piggybacked with a malicious payload (rider), allowing inexpensive malware manufacturing. 
One of the main challenges posed when studying repackaged malware is slicing the app to split benign components apart from the malicious ones. To address this problem, we use differential analysis to isolate software components that are irrelevant to the campaign and study the behavior of malicious riders alone. Our analysis framework relies on collective repositories and recent advances on the systematization of intelligence extracted from multiple anti-virus vendors. We find that since its infancy in 2010, the Android malware ecosystem has changed significantly, both in the type of malicious activity performed by the malicious samples and in the level of obfuscation used by malware to avoid detection. We then show that our framework can aid analysts who attempt to study unknown malware families. Finally, we discuss what our findings mean for Android malware detection research, highlighting areas that need further attention by the research community.},
author = {Guillermo Suarez-Tangil and G. Stringhini},
journal = {ArXiv},
volume = {abs/1801.08115},
pages = {},
doi = {10.1109/tdsc.2020.2982635},
arxivid = {1801.08115},
}

@article{3a0fcbb8a7a1f6af7bee3f620fd20edb47b9cd5b,
title = {Benchmarking Label Dynamics of VirusTotal Engines},
year = {2020},
url = {https://semanticscholar.org/paper/3a0fcbb8a7a1f6af7bee3f620fd20edb47b9cd5b},
abstract = {VirusTotal is the largest online anti-malware scanning service. It is widely used by security researchers for labeling malware data or serving as a comparison baseline. However, several important challenges of using VirusTotal are left unaddressed (e.g., whether VirusTotal labels are already stable, when VirusTotal labels can be trusted), severely harming the correctness of research projects depending on VirusTotal. In this paper, we present VTSet, which contains daily VirusTotal labels on more than 14,000 files over one year. VTSet can be used to build and evaluate various tools to tackle the existing challenges and facilitate the usage of VirusTotal. Besides the data, VTSet also provides a demonstration tool to display many measurement results and a query tool to ease the access of its data. A video demonstration of VTSet is located at the following link: https://youtu.be/aSVaUGHxFi4.},
author = {Shuofei  Zhu and Ziyi  Zhang and Limin  Yang and Linhai  Song and Gang  Wang},
journal = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
volume = {},
pages = {},
doi = {10.1145/3372297.3420013},
}

@article{4db986cb592533fee1ecde11ec96db8e77dbb809,
title = {An Analysis of Android Malware Classification Services},
year = {2021},
url = {https://www.semanticscholar.org/paper/4db986cb592533fee1ecde11ec96db8e77dbb809},
abstract = {The increasing number of Android malware forced antivirus (AV) companies to rely on automated classification techniques to determine the family and class of suspicious samples. The research community relies heavily on such labels to carry out prevalence studies of the threat ecosystem and to build datasets that are used to validate and benchmark novel detection and classification methods. In this work, we carry out an extensive study of the Android malware ecosystem by surveying white papers and reports from 6 key players in the industry, as well as 81 papers from 8 top security conferences, to understand how malware datasets are used by both. We, then, explore the limitations associated with the use of available malware classification services, namely VirusTotal (VT) engines, for determining the family of an Android sample. Using a dataset of 2.47 M Android malware samples, we find that the detection coverage of VT’s AVs is generally very low, that the percentage of samples flagged by any 2 AV engines does not go beyond 52%, and that common families between any pair of AV engines is at best 29%. We rely on clustering to determine the extent to which different AV engine pairs agree upon which samples belong to the same family (regardless of the actual family name) and find that there are discrepancies that can introduce noise in automatic label unification schemes. We also observe the usage of generic labels and inconsistencies within the labels of top AV engines, suggesting that their efforts are directed towards accurate detection rather than classification. Our results contribute to a better understanding of the limitations of using Android malware family labels as supplied by common AV engines.},
author = {Mohammed Rashed and Guillermo Suarez-Tangil},
journal = {Sensors (Basel, Switzerland)},
volume = {21},
pages = {},
doi = {10.3390/s21165671},
pmid = {34451112},
}

@article{6031380b6c3d5d2a9ca6221270ada9e64d28fcde,
title = {RmvDroid: Towards A Reliable Android Malware Dataset with App Metadata},
year = {2019},
url = {https://www.semanticscholar.org/paper/6031380b6c3d5d2a9ca6221270ada9e64d28fcde},
abstract = {A large number of research studies have been focused on detecting Android malware in recent years. As a result, a reliable and large-scale malware dataset is essential to build effective malware classifiers and evaluate the performance of different detection techniques. Although several Android malware benchmarks have been widely used in our research community, these benchmarks face several major limitations. First, most of the existing datasets are outdated and cannot reflect current malware evolution trends. Second, most of them only rely on VirusTotal to label the ground truth of malware, while some anti-virus engines on VirusTotal may not always report reliable results. Third, all of them only contain the apps themselves (apks), while other important app information (e.g., app description, user rating, and app installs) is missing, which greatly limits the usage scenarios of these datasets. In this paper, we have created a reliable Android malware dataset based on Google Play's app maintenance results over several years. We first created four snapshots of Google Play in 2014, 2015, 2017 and 2018 respectively. Then we use VirusTotal to label apps with possible sensitive behaviors, and monitor these apps on Google Play to see whether Google has removed them or not. Based on this approach, we have created a malware dataset containing 9,133 samples that belong to 56 malware families with high confidence. We believe this dataset will boost a series of research studies including Android malware detection and classification, mining apps for anomalies, and app store mining, etc.},
author = {Haoyu Wang and Junjun Si and Hao Li and Y. Guo},
journal = {2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
volume = {},
pages = {404-408},
doi = {10.1109/MSR.2019.00067},
}

@article{119cc98a13db1959e45bfdd6c6760741fa49947d,
title = {Better Malware Ground Truth: Techniques for Weighting Anti-Virus Vendor Labels},
year = {2015},
url = {https://www.semanticscholar.org/paper/119cc98a13db1959e45bfdd6c6760741fa49947d},
abstract = {We examine the problem of aggregating the results of multiple anti-virus (AV) vendors' detectors into a single authoritative ground-truth label for every binary. To do so, we adapt a well-known generative Bayesian model that postulates the existence of a hidden ground truth upon which the AV labels depend. We use training based on Expectation Maximization for this fully unsupervised technique. We evaluate our method using 279,327 distinct binaries from VirusTotal, each of which appeared for the first time between January 2012 and June 2014. Our evaluation shows that our statistical model is consistently more accurate at predicting the future-derived ground truth than all unweighted rules of the form "k out of n" AV detections. In addition, we evaluate the scenario where partial ground truth is available for model building. We train a logistic regression predictor on the partial label information. Our results show that as few as a 100 randomly selected training instances with ground truth are enough to achieve 80% true positive rate for 0.1% false positive rate. In comparison, the best unweighted threshold rule provides only 60% true positive rate at the same false positive rate.},
author = {Alex Kantchelian and M. Tschantz and Sadia Afroz and Brad Miller and Vaishaal Shankar and Rekha Bachwani and A. Joseph and J. Tygar},
journal = {Proceedings of the 8th ACM Workshop on Artificial Intelligence and Security},
volume = {},
pages = {},
doi = {10.1145/2808769.2808780},
}

@article{eb7f0d2a9256a9b7e875cf7107d75dff2bfb61bb,
title = {Effective dataset construction method using Dexofuzzy based on Android malware opcode mining},
year = {2021},
url = {https://www.semanticscholar.org/paper/eb7f0d2a9256a9b7e875cf7107d75dff2bfb61bb},
abstract = {},
author = {Shinho Lee and Wookhyun Jung and Wonrak Lee and HyungGeun Oh and Eui Tak Kim},
journal = {ICT Express},
volume = {},
pages = {},
doi = {10.1016/j.icte.2021.10.001},
}

@article{adf7d8908671a1b987355e1c506162760e4e3b8b,
title = {Program analysis and machine learning techniques for mobile security},
year = {2019},
url = {https://www.semanticscholar.org/paper/adf7d8908671a1b987355e1c506162760e4e3b8b},
abstract = {The rapid rise of the smartphone is mainly due to the availability of mobile applications (apps) that provide a wide range of functionalities. Statistics from International Data Corporation (IDC) has shown that Android is the most popular smartphone platform over the past few years. Due to the openness and low threshold of entering the Android app market, it has the largest collection of mobile apps. Unfortunately, it’s popularity also attracts the unwanted attention of cyber-criminals. McAfee has reported that the number of threats families found in Google Play has increased by 30% in the year 2017, resulting in more than 4 thousand mobile threat families and variants in their sample database. Over the past few years, concerns have been raised with respect to the increasing number of malicious and clone apps infiltrating the Android markets. Android malware may perform a range of malicious activities e.g., leakage of sensitive information or encrypt data and lock the user out of the compromised device for ransom. On the other hand, clone apps are repackaged apps that steal revenue from the original developer of the popular apps. Despite the advances in mobile security, the detection of malicious and clone mobile apps is non-trivial and remains an open problem. In order to differentiate these adversary apps from benign apps, an in-depth understanding of the apps is required. However, due to the arms race between the adversary apps and the detection algorithms, the adversary apps are constantly evolving and becoming more sophisticated. Hence, new and more effective algorithms are imperative. In this thesis, we address the problem of Android security by presenting new program analysis and machine learning approaches we have developed for the vetting of Android apps. The achievements made in this thesis are as follow: 1. We develop a novel approach to detect clone in Android apps by analyzing runtime user interface (UI) information. We take advantage of the unique multiple entry points characteristic of Android apps, to collect the UI information ii efficiently and avoid the need for the tedious process of having to create multiple sets of relevant inputs to navigate through the entire app. An inherent advantageous characteristic of our approach is that is it resilient to code obfuscation since semantics preserving obfuscation techniques do not have any influence on runtime behaviors. The evaluation of the proposed approach was performed on a set of real-world Android apps and the results reveal that it can achieve low false positive rate and false negative rate. We further analyze the results and observe that our approach is effective in detecting different types of repackaging attacks. 2. Third-party libraries (TPLs) are commonly found in Android apps and various reports on the privacy risks and security threats that are brought about by them have surfaced. In addition, there have also been multiple complains of TPLs hindering various program analysis tasks, such as clone detection, static taint analysis, etc. Understandably, since TPLs are typically used as it is, it may include an abundance of unnecessary code to the host app and may dilute the features and increase the complexity of the code analysis, thus affecting the accuracy and scalability of the tasks. A typical and straightforward solution for identifying and excluding the TPLs is to match the name of the packages in the app to a whitelist which holds a list of known TPL package names. However, these whitelists are vulnerable against the commonly employed renaming obfuscation technique and given the fast-paced ecosystem, it is also difficult for the whitelist to be exhaustive. Hence, we propose LibSift, a tool which automates the process of identifying TPLs in Android apps. It identifies TPLs by analyzing the package dependencies of the app allowing it to be resilient to most of the typical obfuscation techniques. 3. In recent years, several promising Machine Learning (ML) based Android malware detection approaches that achieve remarkable results have been proposed in the literature. Most of these approaches are built upon the batch learning model, where a common assumption of such model is that the underlying probability distribution of the observed characteristics belonging to the data source (i.e., malware samples) is stationary. However, apart from the arms race, mobile apps are constantly evolving due to several factors such as environmental changes and adding features. These evolutions cause the distribution of the population to change over time. Moreover, in the real-world use case, the malware detection models are trained on the existing dataset and used to predict forthcoming samples that stream in. Consequently, in the face of malware evolution, the detection accuracy of the model in the real-world scenario will degrade over time. We perform iii a systematic study to examine the challenges faced by state-of-the-art ML based Android malware detection approaches in the presence of concept drift. Furthermore, we propose and evaluate the modification to the approaches that may help them to overcome their limitations in handling streaming features, samples, and classes. 4. Traditionally, extensive feature engineering effort is spent to develop a solution for each of the critical Android program analytics tasks to address the multitude of problems have plagued the Android ecosystem. Hence, we aim to build holistic behavioral profiles of Android apps with rich and multi-modal information (e.g., incorporating several semantic views of an app such as API calls, system calls, etc.). Such profiles could be used to address various downstream program analytics tasks such as malware detection, clone detection, and app recommendation etc. Towards this goal, we design a data-driven Representation Learning (RL) framework named apk2vec which incorporates various state-of-the-art RL paradigm such as semisupervised, multiview and hash embedding techniques to automatically generate succinct and versatile representation (aka profile or embedding) for Android apps. In sum, this thesis proposes three methods and one empirical study with suggestions for Android apps analysis. We address four specific issues that plague Android security, namely, app clone detection, third-party library detection, malware detection, and concept drift. We do so through leveraging on techniques such as program analysis, Machine Learning and Deep Learning.},
author = {C. Soh},
doi = {10.32657/10220/47894},
}

@article{4138c0cff210fe01e935dabca9288b8c5785a356,
title = {A Framework for Cluster and Classifier Evaluation in the Absence of Reference Labels},
year = {2021},
url = {https://www.semanticscholar.org/paper/4138c0cff210fe01e935dabca9288b8c5785a356},
abstract = {In some problem spaces, the high cost of obtaining ground truth labels necessitates use of lower quality reference datasets. It is difficult to benchmark model performance using these datasets, as evaluation results may be biased. We propose a supplement to using reference labels, which we call an approximate ground truth refinement (AGTR). Using an AGTR, we prove that bounds on specific metrics used to evaluate clustering algorithms and multi-class classifiers can be computed without reference labels. We also introduce a procedure that uses an AGTR to identify inaccurate evaluation results produced from datasets of dubious quality. Creating an AGTR requires domain knowledge, and malware family classification is a task with robust domain knowledge approaches that support the construction of an AGTR. We demonstrate our AGTR evaluation framework by applying it to a popular malware labeling tool to diagnose over-fitting in prior testing and evaluate changes whose impact could not be meaningfully quantified under previous data.},
author = {R. J. Joyce and Edward Raff and Charles K. Nicholas},
journal = {Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security},
volume = {},
pages = {},
doi = {10.1145/3474369.3486867},
arxivid = {2109.11126},
}

@article{ec61ad2d0a822ab7977c89f263b8e50c956076dc,
title = {Empirical study of android repackaged applications},
year = {2019},
url = {https://www.semanticscholar.org/paper/ec61ad2d0a822ab7977c89f263b8e50c956076dc},
abstract = {The growing popularity of Android applications has generated increased concerns over the danger of piracy and the spread of malware, and particularly of adware: malware that seeks to present unwanted advertisements to the user. A popular way to distribute malware in the mobile world is through repackaging of legitimate apps. This process consists of downloading, unpacking, manipulating, recompiling an application, and publishing it again in an app store. In this paper, we conduct an empirical study of over 15,000 apps to gain insights into the factors that drive the spread of repackaged apps. We also examine the motivations of developers who publish repackaged apps and those of users who download them, as well as the factors that determine which apps are chosen for repackaging, and the ways in which the apps are modified during the repackaging process. Having observed that adware is particularly prevalent in repackaged apps, we focus on this type of malware and examine how the app is modified when it is injected in an app’s code. Our findings shed much needed light on this class of malware that can be useful to security experts, and allow us to make recommendations that could lead to the creation of more effective malware detection tools, Furthermore, on the basis of our results, we propose a novel app indexing scheme that minimizes the number of comparisons needed to detect repackaged apps.},
author = {K. Khanmohammadi and Neda Ebrahimi and A. Hamou-Lhadj and Raphaël Khoury},
journal = {Empirical Software Engineering},
volume = {24},
pages = {3587 - 3629},
doi = {10.1007/s10664-019-09760-3},
}

@article{f74804eaf20b71da1ad2ebbbb429595c133459c8,
title = {AVclass: A Tool for Massive Malware Labeling},
year = {2016},
url = {https://www.semanticscholar.org/paper/f74804eaf20b71da1ad2ebbbb429595c133459c8},
abstract = {Labeling a malicious executable as a variant of a known family is important for security applications such as triage, lineage, and for building reference datasets in turn used for evaluating malware clustering and training malware classification approaches. Oftentimes, such labeling is based on labels output by antivirus engines. While AV labels are well-known to be inconsistent, there is often no other information available for labeling, thus security analysts keep relying on them. However, current approaches for extracting family information from AV labels are manual and inaccurate. In this work, we describe AVclass, an automatic labeling tool that given the AV labels for a, potentially massive, number of samples outputs the most likely family names for each sample. AVclass implements novel automatic techniques to address 3 key challenges: normalization, removal of generic tokens, and alias detection. We have evaluated AVclass on 10 datasets comprising 8.9 M samples, larger than any dataset used by malware clustering and classification works. AVclass leverages labels from any AV engine, e.g., all 99 AV engines seen in VirusTotal, the largest engine set in the literature. AVclass’s clustering achieves F1 measures up to 93.9 on labeled datasets and clusters are labeled with fine-grained family names commonly used by the AV vendors. We release AVclass to the community.},
author = {Marcos Sebastián and Richard Rivera and Platon Kotzias and Juan Caballero},
doi = {10.1007/978-3-319-45719-2_11},
}

@article{f49a0b44e3c760a9239b2fda3dfefd880f91fb2c,
title = {On labeling Android malware signatures using minhashing and further classification with Structural Equation Models},
year = {2017},
url = {https://www.semanticscholar.org/paper/f49a0b44e3c760a9239b2fda3dfefd880f91fb2c},
abstract = {Multi-scanner Antivirus systems provide insightful information on the nature of a suspect application; however there is often a lack of consensus and consistency between different Anti-Virus engines. In this article, we analyze more than 250 thousand malware signatures generated by 61 different Anti-Virus engines after analyzing 82 thousand different Android malware applications. We identify 41 different malware classes grouped into three major categories, namely Adware, Harmful Threats and Unknown or Generic signatures. We further investigate the relationships between such 41 classes using community detection algorithms from graph theory to identify similarities between them; and we finally propose a Structure Equation Model to identify which Anti-Virus engines are more powerful at detecting each macro-category. As an application, we show how such models can help in identifying whether Unknown malware applications are more likely to be of Harmful or Adware type.},
author = {I. Martín and José Alberto Hernández and Sergio de los Santos},
journal = {ArXiv},
volume = {abs/1709.04186},
pages = {},
arxivid = {1709.04186},
}

@article{b34eb7aa9ee3c89b9d284a20904a8b4a8ef1524d,
title = {Understanding Android App Piggybacking: A Systematic Study of Malicious Code Grafting},
year = {2017},
url = {https://www.semanticscholar.org/paper/b34eb7aa9ee3c89b9d284a20904a8b4a8ef1524d},
abstract = {The Android packaging model offers ample opportunities for malware writers to piggyback malicious code in popular apps, which can then be easily spread to a large user base. Although recent research has produced approaches and tools to identify piggybacked apps, the literature lacks a comprehensive investigation into such phenomenon. We fill this gap by: 1) systematically building a large set of piggybacked and benign apps pairs, which we release to the community; 2) empirically studying the characteristics of malicious piggybacked apps in comparison with their benign counterparts; and 3) providing insights on piggybacking processes. Among several findings providing insights analysis techniques should build upon to improve the overall detection and classification accuracy of piggybacked apps, we show that piggybacking operations not only concern app code, but also extensively manipulates app resource files, largely contradicting common beliefs. We also find that piggybacking is done with little sophistication, in many cases automatically, and often via library code.},
author = {L. Li and Daoyuan Li and Tegawendé F. Bissyandé and Jacques Klein and Y. Le Traon and D. Lo and L. Cavallaro},
journal = {IEEE Transactions on Information Forensics and Security},
volume = {12},
pages = {1269-1284},
doi = {10.1109/TIFS.2017.2656460},
}

@article{63ff1eaf67e3ce76824932c19fb5ccb4bf4b69bd,
title = {A Large-scale Temporal Measurement of Android Malicious Apps: Persistence, Migration, and Lessons Learned},
year = {2021},
url = {https://www.semanticscholar.org/paper/63ff1eaf67e3ce76824932c19fb5ccb4bf4b69bd},
abstract = {We study the temporal dynamics of potentially harmful apps (PHAs) on Android by leveraging 8.8M daily on-device detections collected among 11.7M customers of a popular mobile security product between 2019 and 2020. We show that the current security model of Android, which limits security products to run as regular apps and prevents them from automatically removing malicious apps opens a significant window of opportunity for attackers. Such apps warn users about the newly discovered threats, but users do not promptly act on this information, allowing PHAs to persist on their device for an average of 24 days after they are detected. We also find that while app markets remove PHAs after these become known, there is a significant delay between when PHAs are identified and when they are removed: PHAs persist on Google Play for 77 days on average and 34 days on third party marketplaces. Finally, we find evidence of PHAs migrating to other marketplaces after being removed on the original one. This paper provides an unprecedented view of the Android PHA landscape, showing that current defenses against PHAs on Android are not as effective as commonly thought, and identifying multiple research directions that the security community should pursue, from orchestrating more effective PHA takedowns to devising better alerts for mobile security products.},
author = {Yun Shen and Pierre-Antoine Vervier and G. Stringhini},
journal = {ArXiv},
volume = {abs/2108.04754},
pages = {},
arxivid = {2108.04754},
}

@article{023ad37b1515b095b705c92cdd430044f25fda6d,
title = {Detección y Clasificación de Malware con el Sistema de Análisis de Malware Cuckoo},
year = {2018},
url = {https://www.semanticscholar.org/paper/023ad37b1515b095b705c92cdd430044f25fda6d},
abstract = {Currently malware is still one of the biggest challenges in computer security. The frequent 
release of new variants of samples from the same malware family, due to obfuscation 
techniques used by authors of malicious software, makes malware detection 
and classification a complex problem. The goal of this work is to develop an experimental 
pilot, to evaluate the accuracy of a malware classification approach using the 
Cuckoo SandBox signature module. A set of 16 malware signatures of known families 
are developed, which have been evaluated with two data sets, comprising a total of 16K 
samples of malicious software. The evaluation of our classification approach using a 
reference dataset as the ground thruth reaches a F-Measure value of 91 %.},
author = {Richard Paul Rivera-Guevara},
}

@article{3f4ed8104aa56289692d00a1128f10e0a1a8276d,
title = {Detecting intelligent malware on dynamic Android analysis environments},
year = {2015},
url = {https://www.semanticscholar.org/paper/3f4ed8104aa56289692d00a1128f10e0a1a8276d},
abstract = {In recent years, static and dynamic analysis of Smartphone applications has been popularized. This kind of analysis have assisted in detecting malware among other applications. In order to evade detection on emulator based dynamic analysis environments, number of malware rely on specific details of the emulator and user input, such as IMEI number, button press, phone call, accelerometer readings, etc. Once malware identifies an emulator, it can act benignly and pass the analysis undetected. To enhance the detection capability of dynamic analysis environments, we present a framework which enhances their capibility to detect intelligent mawares. The objective of the framework is twofold, to emulate artificial user behavior and help unravel malware's true behavior. Our framework is divided into two major categories based on dynamic and static properties of a Smartphone. The framework is tested with an open-source sandbox environment and an existing emulator detection application.},
author = {S. Singh and Bharavi Mishra and Saket Singh},
journal = {2015 10th International Conference for Internet Technology and Secured Transactions (ICITST)},
volume = {},
pages = {414-419},
doi = {10.1109/ICITST.2015.7412132},
}

@article{43d9c52b5a65d65ecbfbb01b120bfc4d673912a0,
title = {A Close Look at a Daily Dataset of Malware Samples},
year = {2019},
url = {https://www.semanticscholar.org/paper/43d9c52b5a65d65ecbfbb01b120bfc4d673912a0},
abstract = {The number of unique malware samples is growing out of control. Over the years, security companies have designed and deployed complex infrastructures to collect and analyze this overwhelming number of samples. As a result, a security company can collect more than 1M unique files per day only from its different feeds. These are automatically stored and processed to extract actionable information derived from static and dynamic analysis. However, only a tiny amount of this data is interesting for security researchers and attracts the interest of a human expert. To the best of our knowledge, nobody has systematically dissected these datasets to precisely understand what they really contain. The security community generally discards the problem because of the alleged prevalence of uninteresting samples. In this article, we guide the reader through a step-by-step analysis of the hundreds of thousands Windows executables collected in one day from these feeds. Our goal is to show how a company can employ existing state-of-the-art techniques to automatically process these samples and then perform manual experiments to understand and document what is the real content of this gigantic dataset. We present the filtering steps, and we discuss in detail how samples can be grouped together according to their behavior to support manual verification. Finally, we use the results of this measurement experiment to provide a rough estimate of both the human and computer resources that are required to get to the bottom of the catch of the day.},
author = {Xabier Ugarte-Pedrero and Mariano Graziano and D. Balzarotti},
journal = {ACM Transactions on Privacy and Security (TOPS)},
volume = {22},
pages = {1 - 30},
doi = {10.1145/3291061},
}
